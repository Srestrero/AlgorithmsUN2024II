{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srestrero/AlgorithmsUN2024II/blob/main/LAB_ATQ/srestreporo_LAB_ATQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Ygcz-I08yf"
      },
      "source": [
        "#   Q18 Machine Learning Rolling Basis\n",
        "#   Santiago Restrepo Rojas\n",
        "\n",
        "In this example we predict whether the price will rise or fall by using supervised learning (Random Forest Regressor). This template represents a starting point for developing a system which can take part to the Q18 S&P 500 Stock Long-Short contest.\n",
        "\n",
        "It consists of two parts.\n",
        "\n",
        "* In the **first part** we just perform a global training of the time series using all time series data. We disregard the sequential aspect of the data and use also future data to train past data.\n",
        "\n",
        "* In the **second part** we use the built-in backtester and perform training and prediction on a rolling basis in order to avoid forward looking. Please note that we are using a **specialized** version of the Quantiacs backtester which dramatically speeds up the the backtesting process by retraining your model on a regular basis.\n",
        "\n",
        "**Features for learning**: we will use several technical indicators trying to capture different features. You can have a look at [**Technical Indicators**](https://quantiacs.com/documentation/en/user_guide/technical_indicators.html).\n",
        "\n",
        "Please note that:\n",
        "\n",
        "* Your trading algorithm can open short and long positions.\n",
        "\n",
        "* At each point in time your algorithm can trade all or a subset of the stocks which at that point of time are or were part of the NASDAQ-100 stock index. Note that the composition of this set changes in time, and Quantiacs provides you with an appropriate filter function for selecting them.\n",
        "\n",
        "* The Sharpe ratio of your system since January 1st, 2006, has to be larger than 1.\n",
        "\n",
        "* Your system cannot be a copy of the current examples. We run a correlation filter on the submissions and detect duplicates.\n",
        "\n",
        "* For simplicity we will use a single asset. It pays off to use more assets, ideally uncorrelated, and diversify your positions for a more solid Sharpe ratio.\n",
        "\n",
        "More details on the rules can be found [here](https://quantiacs.com/contest).\n",
        "\n",
        "**Need help?** Check the [**Documentation**](https://quantiacs.com/documentation/en/) and find solutions/report problems in the [**Forum**](https://quantiacs.com/community/categories) section.\n",
        "\n",
        "**More help with Jupyter?** Check the official [**Jupyter**](https://jupyter.org/) page.\n",
        "\n",
        "Once you are done, click on **Submit to the contest** and take part to our competitions.\n",
        "\n",
        "API reference:\n",
        "\n",
        "* **data**: check how to work with [data](https://quantiacs.com/documentation/en/reference/data_load_functions.html);\n",
        "\n",
        "* **backtesting**: read how to run the [simulation](https://quantiacs.com/documentation/en/reference/evaluation.html) and check the results.\n",
        "\n",
        "Need to use the optimizer function to automate tedious tasks?\n",
        "\n",
        "* **optimization**: read more on our [article](https://quantiacs.com/community/topic/29/optimizing-and-monitoring-a-trading-system-with-quantiacs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIdrt6Z408yj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "48011ece-621c-403e-978d-4bb89dbe2174"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
              "// disable widget scrolling\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
        "// disable widget scrolling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v77f-p1F08yk"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import qnt.stats as qnstats\n",
        "import qnt.data as qndata\n",
        "import qnt.output as qnout\n",
        "import qnt.ta as qnta\n",
        "import qnt.backtester as qnbt\n",
        "import qnt.graph as qngraph\n",
        "import qnt.exposure as qnexp\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWEKm75108yk"
      },
      "outputs": [],
      "source": [
        "# Cargar datos del S&P 500\n",
        "snp_stocks_data = qndata.stocks_load_spx_data(min_date='2005-06-01')\n",
        "# Seleccionar los 20 activos más líquidos\n",
        "vol = snp_stocks_data.sel(field=\"vol\")\n",
        "liq = snp_stocks_data.sel(field=\"is_liquid\")\n",
        "close = snp_stocks_data.sel(field=\"close\")\n",
        "money_vol = vol * liq * close\n",
        "total_money_vol = money_vol.sum(dim='time', skipna=True)\n",
        "top_20_assets = total_money_vol.to_pandas().nlargest(20).index.tolist()\n",
        "stock_data = snp_stocks_data.sel(asset=top_20_assets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7P432dR08yl"
      },
      "outputs": [],
      "source": [
        "def get_features(data):\n",
        "    \"\"\"Calculate technical indicators as features\"\"\"\n",
        "    # Precios y volumen\n",
        "    close = data.sel(field=\"close\")\n",
        "    high = data.sel(field=\"high\")\n",
        "    low = data.sel(field=\"low\")\n",
        "    vol = data.sel(field=\"vol\")\n",
        "    liq = data.sel(field=\"is_liquid\")\n",
        "\n",
        "    # Indicadores técnicos\n",
        "    atrs = qnta.atr(high=high, low=low, close=close, ma=14)\n",
        "    sma_20 = qnta.sma(close, 20)\n",
        "    sma_50 = qnta.sma(close, 50)\n",
        "\n",
        "    # Money flow indicators\n",
        "    money_vol = vol * liq * close\n",
        "    total_money_vol = money_vol.sum(dim='asset', skipna=True)\n",
        "    money_vol_share = money_vol / total_money_vol\n",
        "    mvs_mov = qnta.sma(money_vol_share, 135)\n",
        "\n",
        "    # Ratio ATR/Close como en el ejemplo original\n",
        "    ratio = atrs / close\n",
        "\n",
        "    features = xr.concat([\n",
        "        sma_20.assign_coords(field=\"sma20\"),\n",
        "        sma_50.assign_coords(field=\"sma50\"),\n",
        "        atrs.assign_coords(field=\"atr\"),\n",
        "        ratio.assign_coords(field=\"atr_ratio\"),\n",
        "        money_vol_share.assign_coords(field=\"money_vol_share\"),\n",
        "        mvs_mov.assign_coords(field=\"mvs_mov\")\n",
        "    ], dim=\"field\")\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EtPdNjs08yl"
      },
      "outputs": [],
      "source": [
        "# Calcular features\n",
        "my_features = get_features(stock_data)\n",
        "\n",
        "# Mostrar un resumen de los features\n",
        "print(\"Dimensiones de los features:\", my_features.dims)\n",
        "print(\"\\nPrimeros valores para un activo específico:\")\n",
        "print(my_features.isel(asset=0).to_pandas().head())\n",
        "print(\"\\nActivos disponibles:\", my_features.asset.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B230uCny08yl"
      },
      "outputs": [],
      "source": [
        "def get_target_classes(data):\n",
        "    \"\"\"Define target values for ML prediction\"\"\"\n",
        "    close = data.sel(field=\"close\")\n",
        "    future_close = qnta.shift(close, -1)  # Precio del siguiente día\n",
        "\n",
        "    # Calcular retorno porcentual manualmente\n",
        "    future_return = (future_close - close) / close\n",
        "\n",
        "    # Clasificación multi-clase basada en los retornos\n",
        "    target = xr.where(future_return > 0.02, 2,  # Strong up\n",
        "             xr.where(future_return > 0, 1,     # Moderate up\n",
        "             xr.where(future_return > -0.02, 0, # Sideways\n",
        "             -1)))                              # Down\n",
        "\n",
        "    return target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7bi_Hk408ym"
      },
      "outputs": [],
      "source": [
        "# Calcular targets\n",
        "my_targetclass = get_target_classes(stock_data)\n",
        "\n",
        "# Mostrar un resumen de los targets\n",
        "print(\"Dimensiones de los targets:\", my_targetclass.dims)\n",
        "print(\"\\nPrimeros valores para un activo específico:\")\n",
        "print(my_targetclass.isel(asset=0).to_pandas().head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRyk-5hG08ym"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    \"\"\"Constructor for Random Forest model\"\"\"\n",
        "    return RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PhIkez808yn"
      },
      "outputs": [],
      "source": [
        "def train_models(features, targets):\n",
        "    \"\"\"Train models for each asset\"\"\"\n",
        "    asset_name_all = features.coords[\"asset\"].values\n",
        "    models = {}\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    for asset_name in asset_name_all:\n",
        "        try:\n",
        "            # Preparar datos\n",
        "            target_cur = targets.sel(asset=asset_name).dropna(dim=\"time\", how=\"any\")\n",
        "            features_cur = features.sel(asset=asset_name).dropna(dim=\"time\", how=\"any\")\n",
        "\n",
        "            # Alinear features y targets\n",
        "            target_aligned, features_aligned = xr.align(target_cur, features_cur, join=\"inner\")\n",
        "\n",
        "            if len(features_aligned.time) < 10:\n",
        "                logging.warning(f\"Insufficient data for {asset_name}\")\n",
        "                continue\n",
        "\n",
        "            # Preparar datos para el modelo\n",
        "            features_array = features_aligned.transpose(\"time\", \"field\").values\n",
        "            target_array = target_aligned.values\n",
        "\n",
        "            # Verificar que tenemos datos válidos\n",
        "            if len(features_array) != len(target_array):\n",
        "                logging.warning(f\"Data mismatch for {asset_name}\")\n",
        "                continue\n",
        "\n",
        "            # Escalado de características\n",
        "            features_scaled = scaler.fit_transform(features_array)\n",
        "\n",
        "            # Entrenar modelo\n",
        "            model = get_model()\n",
        "            model.fit(features_scaled, target_array)\n",
        "            models[asset_name] = {\n",
        "                'model': model,\n",
        "                'scaler': scaler\n",
        "            }\n",
        "\n",
        "            print(f\"Successfully trained model for {asset_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Error training model for {asset_name}: {str(e)}\")\n",
        "\n",
        "    return models\n",
        "\n",
        "# Entrenar modelos\n",
        "print(\"Iniciando entrenamiento de modelos...\")\n",
        "models = train_models(my_features, my_targetclass)\n",
        "print(f\"Modelos entrenados: {len(models)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FXMwh1008yn"
      },
      "outputs": [],
      "source": [
        "def plot_feature_importance():\n",
        "    \"\"\"Visualiza la importancia de las características para cada modelo\"\"\"\n",
        "    for asset_name, model_dict in models.items():\n",
        "        print(f\"\\nImportancia de características para {asset_name}:\")\n",
        "\n",
        "        # Obtener importancia de características del Random Forest\n",
        "        importance = model_dict['model'].feature_importances_\n",
        "\n",
        "        # Obtener nombres de las características\n",
        "        feature_names = list(my_features.field.values)\n",
        "\n",
        "        # Crear DataFrame para mejor visualización\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': importance\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        # Mostrar valores\n",
        "        for idx, row in importance_df.iterrows():\n",
        "            print(f\"{row['feature']}: {row['importance']:.5f}\")\n",
        "\n",
        "        # Visualización\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(importance_df['feature'], importance_df['importance'])\n",
        "        plt.title(f'Feature Importance for {asset_name}')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Mostrar importancia de características\n",
        "plot_feature_importance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCHXPS0k08yn"
      },
      "outputs": [],
      "source": [
        "def generate_weights(data):\n",
        "    \"\"\"Genera pesos basados en las predicciones del modelo\"\"\"\n",
        "    # Inicializar pesos\n",
        "    weights = xr.zeros_like(data.sel(field=\"close\"))\n",
        "\n",
        "    # Calcular features para predicción\n",
        "    features = get_features(data)\n",
        "\n",
        "    for asset_name, model_dict in models.items():\n",
        "        try:\n",
        "            # Obtener y preparar features\n",
        "            features_cur = features.sel(asset=asset_name).dropna(dim=\"time\", how=\"any\")\n",
        "\n",
        "            if len(features_cur.time) < 1:\n",
        "                print(f\"No hay suficientes datos para {asset_name}\")\n",
        "                continue\n",
        "\n",
        "            # Preparar datos para predicción\n",
        "            features_array = features_cur.transpose(\"time\", \"field\").values\n",
        "\n",
        "            # Escalar features\n",
        "            features_scaled = model_dict['scaler'].transform(features_array)\n",
        "\n",
        "            # Realizar predicción\n",
        "            predictions = model_dict['model'].predict(features_scaled)\n",
        "\n",
        "            # Asignar pesos\n",
        "            weights.loc[dict(asset=asset_name, time=features_cur.time.values)] = predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Error en predicción para {asset_name}: {str(e)}\")\n",
        "\n",
        "    return weights\n",
        "\n",
        "# Generar pesos\n",
        "print(\"Generando predicciones y pesos...\")\n",
        "weights = generate_weights(stock_data)\n",
        "print(\"\\nResumen de pesos generados:\")\n",
        "print(f\"Shape: {weights.shape}\")\n",
        "print(\"\\nEstadísticas descriptivas:\")\n",
        "print(weights.to_pandas().describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtOGjrN008yn"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(data, weights):\n",
        "    \"\"\"Calcula múltiples métricas de rendimiento\"\"\"\n",
        "    try:\n",
        "        # Calcular retornos relativos\n",
        "        returns = qnstats.calc_relative_return(data, weights)\n",
        "\n",
        "        # Calcular Sharpe Ratio\n",
        "        sharpe = qnstats.calc_sharpe_ratio_annualized(returns).values[-1]\n",
        "\n",
        "        # Calcular Sortino Ratio\n",
        "        sortino = qnstats.calc_sortino_ratio(returns).values[-1]\n",
        "\n",
        "        # Calcular máximo drawdown\n",
        "        max_dd = qnstats.calc_max_drawdown(returns).values[-1]\n",
        "\n",
        "        print(\"\\nMétricas de rendimiento:\")\n",
        "        print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "        print(f\"Sortino Ratio: {sortino:.2f}\")\n",
        "        print(f\"Maximum Drawdown: {max_dd:.2%}\")\n",
        "\n",
        "        return {\n",
        "            'sharpe': sharpe,\n",
        "            'sortino': sortino,\n",
        "            'max_drawdown': max_dd\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Error calculando métricas\")\n",
        "        return None\n",
        "\n",
        "# Calcular y mostrar métricas\n",
        "metrics = calculate_metrics(stock_data, weights)\n",
        "if metrics:\n",
        "    # Visualizar retornos acumulados\n",
        "    returns = qnstats.calc_relative_return(stock_data, weights)\n",
        "    cumulative_returns = (1 + returns).cumprod()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(cumulative_returns.time, cumulative_returns)\n",
        "    plt.title('Retornos Acumulados')\n",
        "    plt.xlabel('Tiempo')\n",
        "    plt.ylabel('Retorno Acumulado')\n",
        "    plt.yscale('log')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qnout.write(weights)"
      ],
      "metadata": {
        "id": "Q7L252jIVT61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_portfolio_performance(data, weights, initial_capital=1_000_000):\n",
        "    \"\"\"Calcula el rendimiento del portafolio y la contribución por activo\"\"\"\n",
        "    try:\n",
        "        # Calcular retornos relativos\n",
        "        returns = qnstats.calc_relative_return(data, weights)\n",
        "\n",
        "        # Calcular equity curve (valor del portafolio en el tiempo)\n",
        "        portfolio_value = initial_capital * (1 + returns).cumprod()\n",
        "\n",
        "        # Calcular retornos por activo\n",
        "        asset_returns = {}\n",
        "        final_values = {}\n",
        "        contributions = {}\n",
        "\n",
        "        for asset in weights.asset.values:\n",
        "            # Crear pesos solo para este activo\n",
        "            single_asset_weights = xr.zeros_like(weights)\n",
        "            single_asset_weights.loc[dict(asset=asset)] = weights.sel(asset=asset)\n",
        "\n",
        "            # Calcular retornos para este activo\n",
        "            asset_return = qnstats.calc_relative_return(data, single_asset_weights)\n",
        "            asset_value = initial_capital * (1 + asset_return).cumprod()\n",
        "\n",
        "            asset_returns[asset] = asset_return\n",
        "            final_values[asset] = float(asset_value.isel(time=-1))\n",
        "            contributions[asset] = final_values[asset] - initial_capital\n",
        "\n",
        "        # Ordenar contribuciones por valor\n",
        "        sorted_contributions = dict(sorted(contributions.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        # Mostrar resultados\n",
        "        final_portfolio_value = float(portfolio_value.isel(time=-1))\n",
        "        total_return = ((final_portfolio_value - initial_capital) / initial_capital) * 100\n",
        "\n",
        "        print(f\"\\nAnálisis de Portafolio con Capital Inicial: ${initial_capital:,.2f}\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"Valor Final del Portafolio: ${final_portfolio_value:,.2f}\")\n",
        "        print(f\"Retorno Total: {total_return:.2f}%\")\n",
        "\n",
        "        print(\"\\nContribución por Activo:\")\n",
        "        print(\"-\" * 60)\n",
        "        for asset, contribution in sorted_contributions.items():\n",
        "            pct_contribution = (contribution / (final_portfolio_value - initial_capital)) * 100\n",
        "            print(f\"{asset}:\")\n",
        "            print(f\"  Contribución: ${contribution:,.2f}\")\n",
        "            print(f\"  % del Retorno Total: {pct_contribution:.2f}%\")\n",
        "\n",
        "        # Visualización\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        plt.bar(sorted_contributions.keys(), sorted_contributions.values())\n",
        "        plt.title('Contribución por Activo al Retorno Total')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylabel('Contribución ($)')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Gráfica de evolución del valor del portafolio\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        plt.plot(portfolio_value.time, portfolio_value)\n",
        "        plt.title('Evolución del Valor del Portafolio')\n",
        "        plt.xlabel('Tiempo')\n",
        "        plt.ylabel('Valor ($)')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return {\n",
        "            'final_value': final_portfolio_value,\n",
        "            'total_return': total_return,\n",
        "            'contributions': sorted_contributions\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Error en el cálculo del rendimiento del portafolio\")\n",
        "        return None\n",
        "\n",
        "# Calcular y mostrar el rendimiento del portafolio\n",
        "portfolio_analysis = calculate_portfolio_performance(stock_data, weights, initial_capital=1_000_000)"
      ],
      "metadata": {
        "id": "VF-s11mCVUr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXrl8X6A08yo"
      },
      "source": [
        "The sharpe ratio using the method above follows from **forward looking**. Predictions for (let us say) 2017 know about the relation between features and targets in 2020. Let us visualize the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDdoDNEj08yo"
      },
      "outputs": [],
      "source": [
        "import qnt.graph as qngraph\n",
        "\n",
        "statistics = qnstats.calc_stat(stock_data, weights)\n",
        "\n",
        "display(statistics.to_pandas().tail())\n",
        "\n",
        "performance = statistics.to_pandas()[\"equity\"]\n",
        "qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")\n",
        "\n",
        "display(statistics[-1:].sel(field = [\"sharpe_ratio\"]).transpose().to_pandas())\n",
        "\n",
        "# check for correlations with existing strategies:\n",
        "qnstats.print_correlation(weights,stock_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ0CaYDK08yo"
      },
      "outputs": [],
      "source": [
        "\"\"\"R2 (coefficient of determination) regression score function.\"\"\"\n",
        "r2_score(my_targetclass, weights, multioutput=\"variance_weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igOjZ_SI08yo"
      },
      "outputs": [],
      "source": [
        "\"\"\"The explained variance score explains the dispersion of errors of a given dataset\"\"\"\n",
        "explained_variance_score(my_targetclass, weights, multioutput=\"uniform_average\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY2VfBUh08yo"
      },
      "outputs": [],
      "source": [
        "\"\"\"The explained variance score explains the dispersion of errors of a given dataset\"\"\"\n",
        "mean_absolute_error(my_targetclass, weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLyXNsRX08yo"
      },
      "source": [
        "Let us now use the Quantiacs **backtester** for avoiding **forward looking**.\n",
        "\n",
        "The backtester performs some transformations: it trains the model on one slice of data (using only data from the past) and predicts the weights for the following slice on a rolling basis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TelIKkDE08yp"
      },
      "outputs": [],
      "source": [
        "def train_model(data):\n",
        "    \"\"\"Create and train the model working on an asset-by-asset basis.\"\"\"\n",
        "\n",
        "    asset_name_all = data.coords[\"asset\"].values\n",
        "    features_all   = get_features(data)\n",
        "    target_all     = get_target_classes(data)\n",
        "\n",
        "    models = dict()\n",
        "\n",
        "    for asset_name in asset_name_all:\n",
        "\n",
        "        # drop missing values:\n",
        "        target_cur   = target_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "        features_cur = features_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "\n",
        "        target_for_learn_df, feature_for_learn_df = xr.align(target_cur, features_cur, join=\"inner\")\n",
        "\n",
        "        if len(features_cur.time) < 10:\n",
        "                continue\n",
        "\n",
        "        model = get_model()\n",
        "\n",
        "        try:\n",
        "            model.fit(feature_for_learn_df.values, target_for_learn_df)\n",
        "            models[asset_name] = model\n",
        "\n",
        "        except:\n",
        "            logging.exception(\"model training failed\")\n",
        "\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09Fy9qKn08yp"
      },
      "outputs": [],
      "source": [
        "def predict_weights(models, data):\n",
        "    \"\"\"The model predicts if the price is going up or down.\n",
        "       The prediction is performed for several days in order to speed up the evaluation.\"\"\"\n",
        "\n",
        "    asset_name_all = data.coords[\"asset\"].values\n",
        "    weights = xr.zeros_like(data.sel(field=\"close\"))\n",
        "\n",
        "    for asset_name in asset_name_all:\n",
        "        if asset_name in models:\n",
        "            model = models[asset_name]\n",
        "            features_all = get_features(data)\n",
        "            features_cur = features_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "\n",
        "            if len(features_cur.time) < 1:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                weights.loc[dict(asset=asset_name, time=features_cur.time.values)] = model.predict(features_cur.values)\n",
        "\n",
        "            except KeyboardInterrupt as e:\n",
        "                raise e\n",
        "\n",
        "            except:\n",
        "                logging.exception(\"model prediction failed\")\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1kDB8J408yp"
      },
      "outputs": [],
      "source": [
        "# Calculate weights using the backtester:\n",
        "weights = qnbt.backtest_ml(\n",
        "    train                         = train_model,\n",
        "    predict                       = predict_weights,\n",
        "    train_period                  =  2 *365,  # the data length for training in calendar days\n",
        "    retrain_interval              = 10 *365,  # how often we have to retrain models (calendar days)\n",
        "    retrain_interval_after_submit = 1,        # how often retrain models after submission during evaluation (calendar days)\n",
        "    predict_each_day              = False,    # Is it necessary to call prediction for every day during backtesting?\n",
        "                                              # Set it to True if you suspect that get_features is looking forward.\n",
        "    competition_type              = \"stocks_nasdaq100\",  # competition type\n",
        "    lookback_period               = 365,                 # how many calendar days are needed by the predict function to generate the output\n",
        "    start_date                    = \"2005-01-01\",        # backtest start date\n",
        "    analyze                       = True,\n",
        "    build_plots                   = True  # do you need the chart?\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqmpUnXx08yp"
      },
      "source": [
        "The Sharpe ratio is obviously smaller as the training process is not looking forward (as it happens by processing data on a global basis), but performed on a rolling basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4v8ha008yp"
      },
      "source": [
        "# May I import libraries?\n",
        "\n",
        "Yes, please refer to the file **init.ipynb** in your home directory. You can for example use:\n",
        "\n",
        "! conda install -y scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNWt0TC08yp"
      },
      "source": [
        "# How to load data?\n",
        "\n",
        "Daily stock data for the **Q18 Nasdaq-100** contest can be loaded using:\n",
        "```python\n",
        "data = qndata.stocks.load_ndx_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```\n",
        "\n",
        "Cryptocurrency daily data used for the Q16/Q17 contests can be loaded using:\n",
        "```python\n",
        "data = qndata.cryptodaily.load_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```\n",
        "\n",
        "Futures data for the Q15 contest can be loaded using:\n",
        "```python\n",
        "data= qndata.futures.load_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```\n",
        "\n",
        "BTC Futures data for the Q15 contest can be loaded using:\n",
        "```python\n",
        "data= qndata.cryptofutures.load_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ5ArwVw08yp"
      },
      "source": [
        "# How to view a list of all tickers?\n",
        "\n",
        "```python\n",
        "data.asset.to_pandas().to_list()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3lTHUHl08yp"
      },
      "source": [
        "# How to see which fields are available?\n",
        "\n",
        "```python\n",
        "data.field.to_pandas().to_list()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t2MOtiY08yq"
      },
      "source": [
        "# How to load specific tickers?\n",
        "\n",
        "```python\n",
        "data = qndata.stocks.load_ndx_data(tail=17 * 365, assets=[\"NAS:AAPL\", \"NAS:AMZN\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KWhGisB08yq"
      },
      "source": [
        "# How to select specific tickers after loading all data?\n",
        "\n",
        "```python\n",
        "def get_data_filter(data, assets):\n",
        "    filler= data.sel(asset=assets)\n",
        "    return filler\n",
        "\n",
        "get_data_filter(data, [\"NAS:AAPL\", \"NAS:AMZN\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd8vqMnE08yq"
      },
      "source": [
        "# How to get the prices for the previous day?\n",
        "\n",
        "```python\n",
        "qnta.shift(data.sel(field=\"open\"), periods=1)\n",
        "```\n",
        "\n",
        "or:\n",
        "\n",
        "```python\n",
        "data.sel(field=\"open\").shift(time=1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65KQJVfm08yq"
      },
      "source": [
        "# How to get the Sharpe ratio?\n",
        "\n",
        "```python\n",
        "import qnt.stats as qnstats\n",
        "\n",
        "def get_sharpe(market_data, weights):\n",
        "    rr = qnstats.calc_relative_return(market_data, weights)\n",
        "    sharpe = qnstats.calc_sharpe_ratio_annualized(rr).values[-1]\n",
        "    return sharpe\n",
        "\n",
        "sharpe = get_sharpe(data, weights) # weights.sel(time=slice(\"2006-01-01\",None))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwOk8Xl308yq"
      },
      "source": [
        "# How do I get a list of the top 3 assets ranked by Sharpe ratio?\n",
        "\n",
        "```python\n",
        "import qnt.stats as qnstats\n",
        "\n",
        "data = qndata.stocks.load_ndx_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "\n",
        "def get_best_instruments(data, weights, top_size):\n",
        "    # compute statistics:\n",
        "    stats_per_asset = qnstats.calc_stat(data, weights, per_asset=True)\n",
        "    # calculate ranks of assets by \"sharpe_ratio\":\n",
        "    ranks = (-stats_per_asset.sel(field=\"sharpe_ratio\")).rank(\"asset\")\n",
        "    # select top assets by rank \"top_period\" days ago:\n",
        "    top_period = 1\n",
        "    rank = ranks.isel(time=-top_period)\n",
        "    top = rank.where(rank <= top_size).dropna(\"asset\").asset\n",
        "\n",
        "    # select top stats:\n",
        "    top_stats = stats_per_asset.sel(asset=top.values)\n",
        "\n",
        "    # print results:\n",
        "    print(\"SR tail of the top assets:\")\n",
        "    display(top_stats.sel(field=\"sharpe_ratio\").to_pandas().tail())\n",
        "\n",
        "    print(\"avg SR = \", top_stats[-top_period:].sel(field=\"sharpe_ratio\").mean(\"asset\")[-1].item())\n",
        "    display(top_stats)\n",
        "    return top_stats.coords[\"asset\"].values\n",
        "\n",
        "get_best_instruments(data, weights, 3)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG-Fs9_708yq"
      },
      "source": [
        "# How can I check the results for only the top 3 assets ranked by Sharpe ratio?\n",
        "\n",
        "Select the top assets and then load their data:\n",
        "\n",
        "```python\n",
        "best_assets= get_best_instruments(data, weights, 3)\n",
        "\n",
        "data= qndata.stocks.load_ndx_data(tail = 17*365, assets=best_assets)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNiulG2n08yq"
      },
      "source": [
        "# How can prices be processed?\n",
        "\n",
        "Simply import standard libraries, for example **numpy**:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "high= np.log(data.sel(field=\"high\"))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTyORIIx08yq"
      },
      "source": [
        "# How can you reduce slippage impace when trading?\n",
        "\n",
        "Just apply some technique to reduce turnover:\n",
        "\n",
        "```python\n",
        "def get_lower_slippage(weights, rolling_time=6):\n",
        "    return weights.rolling({\"time\": rolling_time}).max()\n",
        "\n",
        "improved_weights = get_lower_slippage(weights, rolling_time=6)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W70HmbJR08yq"
      },
      "source": [
        "# How to use technical analysis indicators?\n",
        "\n",
        "For available indicators see the source code of the library: /qnt/ta\n",
        "\n",
        "## ATR\n",
        "\n",
        "```python\n",
        "def get_atr(data, days=14):\n",
        "    high = data.sel(field=\"high\") * 1.0\n",
        "    low  = data.sel(field=\"low\") * 1.0\n",
        "    close= data.sel(field=\"close\") * 1.0\n",
        "\n",
        "    return qnta.atr(high, low, close, days)\n",
        "\n",
        "atr= get_atr(data, days=14)\n",
        "```\n",
        "\n",
        "## EMA\n",
        "\n",
        "```python\n",
        "prices= data.sel(field=\"high\")\n",
        "prices_ema= qnta.ema(prices, 15)\n",
        "```\n",
        "\n",
        "## TRIX\n",
        "\n",
        "```python\n",
        "prices= data.sel(field=\"high\")\n",
        "prices_trix= qnta.trix(prices, 15)\n",
        "```\n",
        "\n",
        "## ADL and EMA\n",
        "\n",
        "```python\n",
        "adl= qnta.ad_line(data.sel(field=\"close\")) * 1.0\n",
        "adl_ema= qnta.ema(adl, 18)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCe4gSh908yq"
      },
      "source": [
        "# How can you check the quality of your strategy?\n",
        "\n",
        "```python\n",
        "import qnt.output as qnout\n",
        "qnout.check(weights, data, \"stocks_nasdaq100\")\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```python\n",
        "stat= qnstats.calc_stat(data, weights)\n",
        "display(stat.to_pandas().tail())\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```python\n",
        "import qnt.graph   as qngraph\n",
        "statistics= qnstats.calc_stat(data, weights)\n",
        "display(statistics.to_pandas().tail())\n",
        "\n",
        "performance= statistics.to_pandas()[\"equity\"]\n",
        "qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")\n",
        "\n",
        "display(statistics[-1:].sel(field = [\"sharpe_ratio\"]).transpose().to_pandas())\n",
        "qnstats.print_correlation(weights, data)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZMhFSlf08yr"
      },
      "source": [
        "# An example using pandas\n",
        "\n",
        "One can work with pandas DataFrames at intermediate steps and at the end convert them to xarray data structures:\n",
        "\n",
        "```python\n",
        "def get_price_pct_change(prices):\n",
        "    prices_pandas = prices.to_pandas()\n",
        "    assets = data.coords[\"asset\"].values\n",
        "    for asset in assets:\n",
        "        prices_pandas[asset] = prices_pandas[asset].pct_change()\n",
        "    return prices_pandas\n",
        "\n",
        "prices = data.sel(field=\"close\") * 1.0\n",
        "prices_pct_change = get_price_pct_change(prices).unstack().to_xarray()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEtoDp9l08yr"
      },
      "source": [
        "# How to submit a strategy to the competition?\n",
        "\n",
        "Check that weights are fine:\n",
        "\n",
        "```python\n",
        "import qnt.output as qnout\n",
        "qnout.check(weights, data, \"stocks_nasdaq100\")\n",
        "```\n",
        "\n",
        "If everything is ok, write the weights to file:\n",
        "\n",
        "```python\n",
        "qnout.write(weights)\n",
        "```\n",
        "\n",
        "In your **personal account**:\n",
        "\n",
        "* **choose** a strategy;\n",
        "* click on the **Submit** button;\n",
        "* select the type of competition.\n",
        "\n",
        "At the beginning you will find the strategy under the **Checking** area:\n",
        "\n",
        "* **Sent strategies** > **Checking**.\n",
        "\n",
        "If technical checks are successful, the strategy will go under the **Candidates** area:\n",
        "\n",
        "* **Sent strategies** > **Candidates**.\n",
        "\n",
        "Otherwise it will be **Filtered**:\n",
        "\n",
        "* **Sent strategies** > **Filtered**\n",
        "\n",
        "and you should inspect error and warning messages.\n",
        "\n",
        "Note that a strategy under the **Candidates** area should have a Sharpe ratio larger than 1 for being eligible for a prize. Please check warning messages in your **Candidates** area!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}